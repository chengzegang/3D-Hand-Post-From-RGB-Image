# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Eo9iEi93WYf_2UHTW1DTgdp_A5gsk4wz
"""

import torch.nn as nn

class CNN(nn.Module):
    def __init__(self, image_h, image_w):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 16, 3, padding='same')
        self.relu1 = nn.ReLU()
        self.pool1 = nn.MaxPool2d(2)
        self.norm1 = nn.BatchNorm2d(16)

        self.conv2 = nn.Conv2d(16, 32, 3, padding='same')
        self.relu2 = nn.ReLU()
        self.pool2 = nn.MaxPool2d(2)
        self.norm2 = nn.BatchNorm2d(32)

        self.conv3 = nn.Conv2d(32, 64, 3, padding='same')
        self.relu3 = nn.ReLU()
        self.pool3 = nn.MaxPool2d(2)
        self.norm3 = nn.BatchNorm2d(64)

        self.conv4 = nn.Conv2d(64, 128, 3, padding='same')
        self.relu4 = nn.ReLU()
        self.pool4 = nn.MaxPool2d(2)
        self.norm4 = nn.BatchNorm2d(128)

        self.flat = nn.Flatten()
        self.fc5 = nn.Linear(51200, 42 * 3)
        self.relu5 = nn.ReLU()
        self.fc6 = nn.Linear(42 * 3, 42 * 3)
        self.unflat = nn.Unflatten(1, (42, 3))

    def forward(self, x):
        x = self.relu1(self.conv1(x))
        x = self.pool1(x)
        x = self.norm1(x)

        x = self.relu2(self.conv2(x))
        x = self.pool2(x)
        x = self.norm2(x)

        x = self.relu3(self.conv3(x))
        x = self.pool3(x)
        x = self.norm3(x)

        x = self.relu4(self.conv4(x))
        x = self.pool4(x)
        x = self.norm4(x)

        x = self.flat(x)
        # print(x.shape)
        x = self.relu5(self.fc5(x))
        x = self.fc6(x)

        x = self.unflat(x)
        return x

from os.path import exists
import torch
import numpy as np
import os
import matplotlib.pyplot as plt
import torchvision.models as torch_models
import tensorflow as tf
import torchvision.transforms as transforms
import PIL.Image as Image
from torch.autograd import Variable
 
model = None

device = "cuda" if torch.cuda.is_available() else "cpu"

loader = transforms.Compose([transforms.ToTensor()])

def image_loader(image_name):
    """load image, returns cuda tensor"""
    image = Image.open(image_name)
    image = loader(image).float()
    image = Variable(image, requires_grad=True)
    image = image.unsqueeze(0)  #this is for VGG, may not be needed for ResNet

    print(image.shape)

    return image.cuda()  #assumes that you're using GPU

def forward(trained_model, imagename):
    # TODO: evaluate the image using given model, you may want to do some post-processing

    image = image_loader(imagename)

    result = trained_model(image)
    print(result.shape)

    # torch tensor to np array

    return result.data.cpu().numpy()


def visualize(image, prediction):

    prediction=prediction[0]

    # TODO: project the vectors into a 3d space, visualize it side by side with the original image.

    # Visualize data
    fig = plt.figure(1)
    ax1 = fig.add_subplot(221)
    ax3 = fig.add_subplot(223, projection='3d')
    ax4 = fig.add_subplot(224, projection='3d')

    ax1.imshow(image)

    # show scattered skeleton points

    kp_visible = np.ones(42)
    kp_visible = kp_visible == kp_visible

    ax3.scatter(prediction[kp_visible, 0], prediction[ kp_visible, 1], prediction[kp_visible,  2])

    ax3.view_init(azim=-90.0, elev=-90.0)  # aligns the 3d coord with the camera view
    ax3.set_xlabel('x')
    ax3.set_ylabel('y')
    ax3.set_zlabel('z')

    # plot the skeleton in 3d space

    kp_visible = np.ones(5)
    kp_visible = kp_visible == kp_visible

    # Keypoints available:
    # 0: left wrist,
    # 1-4: left thumb [tip to palm],
    finger = np.flip(np.vstack((prediction[1:5], prediction[0])))
    ax4.plot(finger[kp_visible, 0], finger[kp_visible, 1], finger[kp_visible, 2])
    # 5-8: left index,
    finger = np.flip(np.vstack((prediction[5:9], prediction[0])))
    ax4.plot(finger[kp_visible, 0], finger[kp_visible, 1], finger[kp_visible, 2])
    # 9-12: 3 finger,
    finger = np.flip(np.vstack((prediction[9:13], prediction[0])))
    ax4.plot(finger[kp_visible, 0], finger[kp_visible, 1], finger[kp_visible, 2])
    # 13-16 4 finger
    finger = np.flip(np.vstack((prediction[13:17], prediction[0])))
    ax4.plot(finger[kp_visible, 0], finger[kp_visible, 1], finger[kp_visible, 2])
    # 17-20: left pinky,
    finger = np.flip(np.vstack((prediction[17:21], prediction[0])))
    ax4.plot(finger[kp_visible, 0], finger[kp_visible, 1], finger[kp_visible, 2])

    # 21: right wrist,
    # 22-25: right thumb,
    finger = np.flip(np.vstack((prediction[22:26], prediction[21])))
    ax4.plot(finger[kp_visible, 0], finger[kp_visible, 1], finger[kp_visible, 2])
    # 26-29: 2 finger
    finger = np.flip(np.vstack((prediction[26:30], prediction[21])))
    ax4.plot(finger[kp_visible, 0], finger[kp_visible, 1], finger[kp_visible, 2])
    # 30-33: 3 finger
    finger = np.flip(np.vstack((prediction[30:34], prediction[21])))
    ax4.plot(finger[kp_visible, 0], finger[kp_visible, 1], finger[kp_visible, 2])
    # 34-37: 4 finger
    finger = np.flip(np.vstack((prediction[34:38], prediction[21])))
    ax4.plot(finger[kp_visible, 0], finger[kp_visible, 1], finger[kp_visible, 2])
    # 38-41: right pinky
    finger = np.flip(np.vstack((prediction[38:42], prediction[21])))
    ax4.plot(finger[kp_visible, 0], finger[kp_visible, 1], finger[kp_visible, 2])

    ax4.set_xlabel('x')
    ax4.set_ylabel('y')
    ax4.set_zlabel('z')

    plt.show()

    return 0


def main(model_type='CNN', model_param_path='param.pt'):
    global model
    if model_type == 'CNN':
        model = CNN(320, 320).to(device)

    if exists(model_param_path):
        model.load_state_dict(torch.load(model_param_path))
        model.to(device)

    # TODO: implementing eval and visualize functions, use these two function to visualize skeleton of input hand image.
    set_id = 'evaluation'
    sample_id = 1

    image = plt.imread(os.path.join('00010.png'))
    prediction = forward(model, '00010.png')

    print(prediction.shape)

    visualize(image, prediction)

    return 0


if __name__ == "__main__":
    main()